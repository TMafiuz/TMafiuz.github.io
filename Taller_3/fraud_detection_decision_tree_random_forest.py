import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, auc
)
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaci√≥n
plt.style.use('default')
sns.set_palette("husl")

print("=" * 80)
print("AN√ÅLISIS DE DETECCI√ìN DE FRAUDE")
print("√Årboles de Decisi√≥n vs Random Forest")
print("=" * 80)

# 2. CARGA Y EXPLORACI√ìN DE DATOS
print("\n2. CARGA Y EXPLORACI√ìN DE DATOS")
print("-" * 40)

# Cargar los diferentes archivos de datos
print("Cargando archivos de datos...")

# Cargar datos de transacciones
transaction_records = pd.read_csv(r'Taller_3\Fraude\Data\Transaction Data\transaction_records.csv')
fraud_indicators = pd.read_csv(r'Taller_3\Fraude\Data\Fraudulent Patterns\fraud_indicators.csv')
customer_data = pd.read_csv(r'Taller_3\Fraude\Data\Customer Profiles\customer_data.csv')
amount_data = pd.read_csv(r'Taller_3\Fraude\Data\Transaction Amounts\amount_data.csv')

print("‚úì Archivos cargados exitosamente")

# Combinar los datos
print("\nCombinando datasets...")
# Unir transacciones con indicadores de fraude
df_base = pd.merge(transaction_records, fraud_indicators, on='TransactionID', how='inner')

# Unir con datos de clientes
df_base = pd.merge(df_base, customer_data, on='CustomerID', how='left')

# Unir con datos de montos (si es diferente de Amount en transaction_records)
if 'TransactionAmount' in amount_data.columns:
    df_base = pd.merge(df_base, amount_data, on='TransactionID', how='left')
    # Si hay diferencias entre Amount y TransactionAmount, usar TransactionAmount
    df_base['Amount'] = df_base['TransactionAmount'].fillna(df_base['Amount'])
    df_base = df_base.drop('TransactionAmount', axis=1)

print(f"‚úì Dataset combinado creado")
print(f"Dimensiones del dataset: {df_base.shape}")
print(f"Variables disponibles: {list(df_base.columns)}")

# Verificar datos
print(f"\nPrimeras 5 filas del dataset combinado:")
print(df_base.head())

print(f"\nInformaci√≥n sobre valores faltantes:")
print(df_base.isnull().sum())

print(f"\nDistribuci√≥n de fraude (variable objetivo):")
fraud_counts = df_base['FraudIndicator'].value_counts()
print(fraud_counts)
print(f"Tasa de fraude: {df_base['FraudIndicator'].mean():.2%}")

# Estad√≠sticas de las transacciones
print(f"\nEstad√≠sticas de transacciones:")
print(f"Monto promedio: ${df_base['Amount'].mean():.2f}")
print(f"Monto mediano: ${df_base['Amount'].median():.2f}")
print(f"Monto m√≠nimo: ${df_base['Amount'].min():.2f}")
print(f"Monto m√°ximo: ${df_base['Amount'].max():.2f}")

print(f"\nEdad promedio de clientes: {df_base['Age'].mean():.1f} a√±os")

# 3. PREPROCESAMIENTO DE DATOS
print("\n3. PREPROCESAMIENTO DE DATOS")
print("-" * 40)

# Crear una copia para el preprocesamiento
data = df_base.copy()

print("Pasos de preprocesamiento:")
print("1. Manejo de valores faltantes")
print("2. Creaci√≥n de caracter√≠sticas derivadas")
print("3. Codificaci√≥n de variables categ√≥ricas")

# Manejo de valores faltantes
data['Age'].fillna(data['Age'].median(), inplace=True)
print("‚úì Valores faltantes de Age imputados con la mediana")

# Crear caracter√≠sticas derivadas para mejorar la detecci√≥n
print("\nCreando caracter√≠sticas derivadas:")

# Caracter√≠sticas basadas en el monto de la transacci√≥n
data['AmountZScore'] = (data['Amount'] - data['Amount'].mean()) / data['Amount'].std()
data['IsHighAmount'] = (data['Amount'] > data['Amount'].quantile(0.95)).astype(int)
data['IsLowAmount'] = (data['Amount'] < data['Amount'].quantile(0.05)).astype(int)

# Caracter√≠sticas basadas en la edad del cliente
data['IsYoungCustomer'] = (data['Age'] < 25).astype(int)
data['IsOldCustomer'] = (data['Age'] > 60).astype(int)

# Caracter√≠stica de riesgo combinada
data['RiskScore'] = data['IsHighAmount'] + data['IsYoungCustomer'] + data['IsOldCustomer']

print("‚úì Caracter√≠sticas derivadas creadas:")
print("  - AmountZScore: Puntuaci√≥n Z del monto")
print("  - IsHighAmount: Indicador de monto alto")
print("  - IsLowAmount: Indicador de monto bajo")
print("  - IsYoungCustomer: Cliente joven (<25 a√±os)")
print("  - IsOldCustomer: Cliente mayor (>60 a√±os)")
print("  - RiskScore: Puntuaci√≥n de riesgo combinada")

# Seleccionar caracter√≠sticas finales para el modelo
feature_columns = [
    'Amount', 'Age', 'AmountZScore', 'IsHighAmount', 'IsLowAmount', 
    'IsYoungCustomer', 'IsOldCustomer', 'RiskScore'
]

X = data[feature_columns]
y = data['FraudIndicator']

print(f"\nCaracter√≠sticas finales: {feature_columns}")
print(f"Forma de X: {X.shape}")
print(f"Forma de y: {y.shape}")

# Divisi√≥n de datos con estratificaci√≥n para manejar el desbalance
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nDivisi√≥n de datos:")
print(f"- Entrenamiento: {X_train.shape[0]} muestras")
print(f"  * Fraudes: {y_train.sum()} ({y_train.mean():.2%})")
print(f"  * Leg√≠timas: {(y_train == 0).sum()} ({(y_train == 0).mean():.2%})")
print(f"- Prueba: {X_test.shape[0]} muestras") 
print(f"  * Fraudes: {y_test.sum()} ({y_test.mean():.2%})")
print(f"  * Leg√≠timas: {(y_test == 0).sum()} ({(y_test == 0).mean():.2%})")

# 4. CONSTRUCCI√ìN Y ENTRENAMIENTO DE MODELOS
print("\n4. CONSTRUCCI√ìN Y ENTRENAMIENTO DE MODELOS")
print("-" * 40)

# 4.1 √Årbol de Decisi√≥n
print("\n4.1 √ÅRBOL DE DECISI√ìN - OPTIMIZADO PARA DETECCI√ìN DE FRAUDE")
print("=" * 65)
print("DESAF√çO: Detectar fraudes en un dataset EXTREMADAMENTE DESBALANCEADO")
print("‚Ä¢ Solo 4.5% de transacciones son fraudulentas")
print("‚Ä¢ El modelo debe ser muy sensible para capturar patrones raros")
print("‚Ä¢ Balance cr√≠tico entre detectar fraudes y evitar falsas alarmas")
print()
print("CONFIGURACI√ìN ESPECIALIZADA PARA FRAUDE:")
print("‚îå‚îÄ max_depth=8:")
print("‚îÇ  ‚Ä¢ Mayor profundidad que otros casos (Titanic=5, Iris=4)")
print("‚îÇ  ‚Ä¢ Permite capturar patrones complejos de fraude")
print("‚îÇ  ‚Ä¢ Los fraudes pueden tener reglas de detecci√≥n m√°s elaboradas")
print("‚îÇ  ‚Ä¢ Riesgo controlado de overfitting por class_weight='balanced'")
print("‚îÇ")
print("‚îå‚îÄ min_samples_split=10:")
print("‚îÇ  ‚Ä¢ Reducido vs Titanic (20) para mayor sensibilidad")
print("‚îÇ  ‚Ä¢ Permite divisiones con menos muestras (importante para clase minoritaria)")
print("‚îÇ  ‚Ä¢ Facilita la detecci√≥n de patrones de fraude raros")
print("‚îÇ")
print("‚îå‚îÄ min_samples_leaf=5:")
print("‚îÇ  ‚Ä¢ Hojas m√°s peque√±as para capturar casos espec√≠ficos de fraude")
print("‚îÇ  ‚Ä¢ Balance entre especificidad y generalizaci√≥n")
print("‚îÇ  ‚Ä¢ Permite reglas de detecci√≥n muy precisas")
print("‚îÇ")
print("‚îå‚îÄ class_weight='balanced': ¬°CR√çTICO PARA FRAUDE!")
print("‚îÇ  ‚Ä¢ Autom√°ticamente ajusta pesos: Leg√≠timo=0.52, Fraude=11.1")
print("‚îÇ  ‚Ä¢ Penaliza M√ÅS los errores en la clase minoritaria (fraudes)")
print("‚îÇ  ‚Ä¢ Fuerza al modelo a prestar m√°s atenci√≥n a los fraudes")
print("‚îÇ  ‚Ä¢ Sin esto, el modelo ignorar√≠a completamente los fraudes")
print("‚îÇ")
print("‚îî‚îÄ random_state=42: Reproducibilidad de experimentos")
print()
print("ESTRATEGIA DE DETECCI√ìN:")
print("‚Ä¢ Priorizar RECALL sobre Precision (mejor detectar fraudes extra)")
print("‚Ä¢ Un fraude no detectado cuesta $100, una falsa alarma $1")
print("‚Ä¢ El √°rbol crear√° reglas muy espec√≠ficas para patrones fraudulentos")
print()

dt_classifier = DecisionTreeClassifier(
    max_depth=8,           
    min_samples_split=10,  
    min_samples_leaf=5,    
    class_weight='balanced',
    random_state=42
)

print("Entrenando √Årbol de Decisi√≥n especializado en fraude...")
dt_classifier.fit(X_train, y_train)

# Calcular pesos reales aplicados cuando class_weight='balanced'
# F√≥rmula: n_samples / (n_classes * np.bincount(y))
weight_0 = len(y_train) / (2 * (y_train == 0).sum())  # Peso para clase leg√≠tima
weight_1 = len(y_train) / (2 * (y_train == 1).sum())  # Peso para clase fraude

print("‚úì √Årbol de Decisi√≥n entrenado exitosamente")
print(f"  ‚Ä¢ Profundidad m√°xima configurada: {dt_classifier.max_depth}")
print(f"  ‚Ä¢ Profundidad real alcanzada: {dt_classifier.get_depth()}")
print(f"  ‚Ä¢ N√∫mero de hojas: {dt_classifier.get_n_leaves()}")
print(f"  ‚Ä¢ Peso clase leg√≠tima (0): {weight_0:.3f}")
print(f"  ‚Ä¢ Peso clase fraude (1): {weight_1:.1f} ‚Üê ¬°{weight_1/weight_0:.1f}x m√°s importante!")
print(f"  ‚Ä¢ Balance de clases: {'‚úì ACTIVADO' if dt_classifier.class_weight == 'balanced' else '‚úó Desactivado'}")

# 4.2 Random Forest
print("\n4.2 RANDOM FOREST - ENSEMBLE PARA DETECCI√ìN DE FRAUDE")
print("=" * 65)
print("TEOR√çA DEL ENSEMBLE PARA FRAUDE:")
print("‚Ä¢ Combina 100 'detectores de fraude' independientes")
print("‚Ä¢ Cada √°rbol ve una muestra diferente de transacciones (bootstrap)")
print("‚Ä¢ Algunos √°rboles se especializar√°n en diferentes tipos de fraude")
print("‚Ä¢ El voto mayoritario reduce falsos positivos")
print()
print("¬øPOR QU√â ENSEMBLE EN FRAUDE?")
print("‚îå‚îÄ Diversidad de Patrones:")
print("‚îÇ  ‚Ä¢ Fraude por monto alto vs fraude por cliente joven")
print("‚îÇ  ‚Ä¢ Diferentes √°rboles pueden especializarse en cada patr√≥n")
print("‚îÇ  ‚Ä¢ Captura m√∫ltiples 'firmas' de comportamiento fraudulento")
print("‚îÇ")
print("‚îå‚îÄ Robustez ante Outliers:")
print("‚îÇ  ‚Ä¢ Los fraudes son inherentemente 'outliers'")
print("‚îÇ  ‚Ä¢ Un √°rbol individual podr√≠a ser enga√±ado por casos raros")
print("‚îÇ  ‚Ä¢ El ensemble es m√°s estable ante variaciones extremas")
print("‚îÇ")
print("‚îå‚îÄ Reducci√≥n de Varianza:")
print("‚îÇ  ‚Ä¢ Importante cuando hay pocos ejemplos de fraude")
print("‚îÇ  ‚Ä¢ Cada √°rbol entrena con ~32 fraudes (bootstrap)")
print("‚îÇ  ‚Ä¢ El promedio de 100 √°rboles es m√°s confiable")
print("‚îÇ")
print("‚îî‚îÄ Estimaci√≥n de Confianza:")
print("   ‚Ä¢ % de √°rboles que votan 'fraude' = nivel de sospecha")
print("   ‚Ä¢ √ötil para establecer umbrales de alerta")
print()
print("CONFIGURACI√ìN DEL ENSEMBLE:")
print("‚îå‚îÄ n_estimators=100:")
print("‚îÇ  ‚Ä¢ 100 detectores independientes")
print("‚îÇ  ‚Ä¢ Cada uno entrena con ~640 transacciones (bootstrap)")
print("‚îÇ  ‚Ä¢ Balance entre diversidad y eficiencia computacional")
print("‚îÇ")
print("‚îå‚îÄ max_depth=8:")
print("‚îÇ  ‚Ä¢ Misma profundidad que √°rbol individual")
print("‚îÇ  ‚Ä¢ Cada √°rbol puede crear reglas complejas")
print("‚îÇ  ‚Ä¢ La diversidad viene del bootstrap, no de √°rboles simples")
print("‚îÇ")
print("‚îå‚îÄ class_weight='balanced':")
print("‚îÇ  ‚Ä¢ ¬°MUY IMPORTANTE! Aplicado a cada √°rbol del ensemble")
print("‚îÇ  ‚Ä¢ Sin esto, Random Forest ignorar√≠a completamente los fraudes")
print("‚îÇ  ‚Ä¢ Cada √°rbol individual est√° sesgado hacia detecci√≥n")
print("‚îÇ")
print("‚îî‚îÄ n_jobs=-1: Paralelizaci√≥n (100 √°rboles toman tiempo)")
print()

rf_classifier = RandomForestClassifier(
    n_estimators=100,      
    max_depth=8,           
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1              
)

print("Entrenando Random Forest (100 detectores de fraude)...")
rf_classifier.fit(X_train, y_train)
print("‚úì Random Forest entrenado exitosamente")
print(f"  ‚Ä¢ N√∫mero de detectores (√°rboles): {rf_classifier.n_estimators}")
print(f"  ‚Ä¢ Profundidad m√°xima por detector: {rf_classifier.max_depth}")
print(f"  ‚Ä¢ Transacciones por detector: ~{int(0.632 * len(X_train))}")
print(f"  ‚Ä¢ Fraudes esperados por detector: ~{int(0.632 * (y_train == 1).sum())}")
print(f"  ‚Ä¢ Caracter√≠sticas evaluadas por split: ‚àö8 ‚âà 3")
print(f"  ‚Ä¢ Balance de clases: {'‚úì ACTIVADO en cada √°rbol' if rf_classifier.class_weight == 'balanced' else '‚úó Desactivado'}")
print(f"  ‚Ä¢ Procesamiento paralelo: ‚úì Todos los cores")

print("\n‚ö†Ô∏è  DESAF√çO ESPEC√çFICO DEL ENSEMBLE EN FRAUDE:")
print("‚Ä¢ Random Forest puede ser 'demasiado conservador' con clases desbalanceadas")
print("‚Ä¢ Cada √°rbol ve pocos fraudes (bootstrap sampling)")
print("‚Ä¢ El voto mayoritario puede diluir se√±ales de fraude d√©biles")
print("‚Ä¢ class_weight='balanced' es ESENCIAL para compensar este efecto")
print("‚Ä¢ Alternativamente se podr√≠a usar t√©cnicas de oversampling (SMOTE)")

# 5. EVALUACI√ìN Y COMPARACI√ìN DE MODELOS
print("\n5. EVALUACI√ìN Y COMPARACI√ìN DE MODELOS")
print("-" * 40)

# Predicciones
dt_pred = dt_classifier.predict(X_test)
dt_pred_proba = dt_classifier.predict_proba(X_test)[:, 1]

rf_pred = rf_classifier.predict(X_test)
rf_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]

# Funci√≥n para calcular m√©tricas de fraude
def calcular_metricas_fraude(y_true, y_pred, y_pred_proba, modelo_nombre):
    print(f"\nM√âTRICAS PARA {modelo_nombre.upper()}")
    print("-" * 30)
    
    # M√©tricas b√°sicas
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    
    print(f"Precisi√≥n (Accuracy): {accuracy:.4f}")
    print(f"Precisi√≥n (Precision): {precision:.4f}")
    print(f"Exhaustividad (Recall): {recall:.4f}")
    print(f"Puntuaci√≥n F1: {f1:.4f}")
    
    # En detecci√≥n de fraude, el Recall es CR√çTICO
    print(f"\n‚ö†Ô∏è  AN√ÅLISIS CR√çTICO PARA FRAUDE:")
    print(f"   Recall (Sensibilidad): {recall:.4f}")
    print(f"   ‚Üí Porcentaje de fraudes detectados: {recall:.1%}")
    print(f"   Precision: {precision:.4f}")
    print(f"   ‚Üí Porcentaje de alertas que son fraude real: {precision:.1%}")
    
    # Matriz de confusi√≥n con interpretaci√≥n de fraude
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    print(f"\nMatriz de Confusi√≥n:")
    print(f"                 Predicho")
    print(f"              Leg√≠timo  Fraude")
    print(f"Real Leg√≠timo    {tn:6d}   {fp:6d}")
    print(f"     Fraude      {fn:6d}   {tp:6d}")
    
    print(f"\nInterpretaci√≥n de errores:")
    print(f"‚Ä¢ Falsos Positivos (FP): {fp} - Transacciones leg√≠timas marcadas como fraude")
    print(f"‚Ä¢ Falsos Negativos (FN): {fn} - ¬°FRAUDES NO DETECTADOS! (MUY CR√çTICO)")
    print(f"‚Ä¢ Verdaderos Positivos (TP): {tp} - Fraudes correctamente detectados")
    print(f"‚Ä¢ Verdaderos Negativos (TN): {tn} - Transacciones leg√≠timas correctas")
    
    # Especificidad (importante para reducir falsos positivos)
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    print(f"‚Ä¢ Especificidad: {specificity:.4f} - Porcentaje de leg√≠timas correctamente clasificadas")
    
    # ROC AUC
    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)
    roc_auc = auc(fpr, tpr)
    print(f"‚Ä¢ AUC-ROC: {roc_auc:.4f}")
    
    return {
        'accuracy': accuracy, 'precision': precision, 'recall': recall, 
        'f1': f1, 'auc': roc_auc, 'specificity': specificity,
        'fpr': fpr, 'tpr': tpr, 'cm': cm, 
        'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn
    }

# Calcular m√©tricas para ambos modelos
dt_metrics = calcular_metricas_fraude(y_test, dt_pred, dt_pred_proba, "√Årbol de Decisi√≥n")
rf_metrics = calcular_metricas_fraude(y_test, rf_pred, rf_pred_proba, "Random Forest")

# 6. AN√ÅLISIS COMPARATIVO
print("\n6. AN√ÅLISIS COMPARATIVO")
print("-" * 40)

# Comparaci√≥n de m√©tricas
metricas_comparacion = pd.DataFrame({
    '√Årbol de Decisi√≥n': [
        dt_metrics['accuracy'], dt_metrics['precision'], 
        dt_metrics['recall'], dt_metrics['f1'], dt_metrics['auc']
    ],
    'Random Forest': [
        rf_metrics['accuracy'], rf_metrics['precision'], 
        rf_metrics['recall'], rf_metrics['f1'], rf_metrics['auc']
    ]
}, index=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC'])

print("Comparaci√≥n de M√©tricas:")
print(metricas_comparacion.round(4))

# Para fraude, el Recall es m√°s importante que la Precision
print(f"\nüéØ AN√ÅLISIS ESPEC√çFICO PARA DETECCI√ìN DE FRAUDE:")
print(f"{'M√©trica':<15} {'√Årbol':<10} {'Random Forest':<15} {'Mejor':<15}")
print("-" * 55)
print(f"{'Recall':<15} {dt_metrics['recall']:<10.4f} {rf_metrics['recall']:<15.4f} "
      f"{'Random Forest' if rf_metrics['recall'] > dt_metrics['recall'] else '√Årbol':<15}")
print(f"{'Precision':<15} {dt_metrics['precision']:<10.4f} {rf_metrics['precision']:<15.4f} "
      f"{'Random Forest' if rf_metrics['precision'] > dt_metrics['precision'] else '√Årbol':<15}")
print(f"{'F1-Score':<15} {dt_metrics['f1']:<10.4f} {rf_metrics['f1']:<15.4f} "
      f"{'Random Forest' if rf_metrics['f1'] > dt_metrics['f1'] else '√Årbol':<15}")

# Costo de errores en fraude
costo_fn = 100  # Costo de no detectar un fraude (muy alto)
costo_fp = 1    # Costo de una falsa alarma (bajo)

dt_costo = (dt_metrics['fn'] * costo_fn) + (dt_metrics['fp'] * costo_fp)
rf_costo = (rf_metrics['fn'] * costo_fn) + (rf_metrics['fp'] * costo_fp)

print(f"\nüí∞ AN√ÅLISIS DE COSTO-BENEFICIO:")
print(f"Asumiendo: Costo de fraude no detectado = ${costo_fn}, Costo de falsa alarma = ${costo_fp}")
print(f"Costo total √Årbol de Decisi√≥n: ${dt_costo}")
print(f"Costo total Random Forest: ${rf_costo}")
mejor_costo = 'Random Forest' if rf_costo < dt_costo else '√Årbol de Decisi√≥n'
print(f"Mejor modelo por costo: {mejor_costo}")

# 7. VISUALIZACIONES
print("\n7. GENERANDO VISUALIZACIONES")
print("-" * 40)

# Configurar subplots
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle('An√°lisis Detecci√≥n de Fraude: √Årboles de Decisi√≥n vs Random Forest', fontsize=16)

# 7.1 Distribuci√≥n de montos por fraude
axes[0,0].hist(data[data['FraudIndicator']==0]['Amount'], bins=30, alpha=0.7, 
              label='Transacciones Leg√≠timas', color='green')
axes[0,0].hist(data[data['FraudIndicator']==1]['Amount'], bins=30, alpha=0.7, 
              label='Transacciones Fraudulentas', color='red')
axes[0,0].set_xlabel('Monto de Transacci√≥n')
axes[0,0].set_ylabel('Frecuencia')
axes[0,0].set_title('Distribuci√≥n de Montos por Tipo')
axes[0,0].legend()

# 7.2 Distribuci√≥n de edades por fraude
axes[0,1].hist(data[data['FraudIndicator']==0]['Age'], bins=20, alpha=0.7, 
              label='Clientes Leg√≠timos', color='green')
axes[0,1].hist(data[data['FraudIndicator']==1]['Age'], bins=20, alpha=0.7, 
              label='Clientes con Fraude', color='red')
axes[0,1].set_xlabel('Edad del Cliente')
axes[0,1].set_ylabel('Frecuencia')
axes[0,1].set_title('Distribuci√≥n de Edades por Tipo')
axes[0,1].legend()

# 7.3 Matriz de Confusi√≥n - √Årbol de Decisi√≥n
sns.heatmap(dt_metrics['cm'], annot=True, fmt='d', cmap='Blues',
           xticklabels=['Leg√≠timo', 'Fraude'],
           yticklabels=['Leg√≠timo', 'Fraude'], ax=axes[0,2])
axes[0,2].set_title('Matriz de Confusi√≥n - √Årbol de Decisi√≥n')
axes[0,2].set_ylabel('Valores Reales')
axes[0,2].set_xlabel('Valores Predichos')

# 7.4 Matriz de Confusi√≥n - Random Forest
sns.heatmap(rf_metrics['cm'], annot=True, fmt='d', cmap='Greens',
           xticklabels=['Leg√≠timo', 'Fraude'],
           yticklabels=['Leg√≠timo', 'Fraude'], ax=axes[1,0])
axes[1,0].set_title('Matriz de Confusi√≥n - Random Forest')
axes[1,0].set_ylabel('Valores Reales')
axes[1,0].set_xlabel('Valores Predichos')

# 7.5 Comparaci√≥n de M√©tricas
metricas_comparacion.plot(kind='bar', ax=axes[1,1])
axes[1,1].set_title('Comparaci√≥n de M√©tricas')
axes[1,1].set_ylabel('Puntuaci√≥n')
axes[1,1].tick_params(axis='x', rotation=45)
axes[1,1].legend()

# 7.6 Curvas ROC
axes[1,2].plot(dt_metrics['fpr'], dt_metrics['tpr'], 
              label=f'√Årbol de Decisi√≥n (AUC = {dt_metrics["auc"]:.3f})', linewidth=2)
axes[1,2].plot(rf_metrics['fpr'], rf_metrics['tpr'], 
              label=f'Random Forest (AUC = {rf_metrics["auc"]:.3f})', linewidth=2)
axes[1,2].plot([0, 1], [0, 1], 'k--', label='L√≠nea Base')
axes[1,2].set_xlabel('Tasa de Falsos Positivos')
axes[1,2].set_ylabel('Tasa de Verdaderos Positivos')
axes[1,2].set_title('Curvas ROC')
axes[1,2].legend()

plt.tight_layout()
plt.savefig('fraud_detection_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# 8. IMPORTANCIA DE CARACTER√çSTICAS
print("\n8. IMPORTANCIA DE CARACTER√çSTICAS")
print("-" * 40)

importancias_rf = rf_classifier.feature_importances_
importancias_dt = dt_classifier.feature_importances_
indices = np.argsort(importancias_rf)[::-1]

print("Ranking de importancia de caracter√≠sticas:")
print(f"{'Rank':<5} {'Caracter√≠stica':<20} {'Random Forest':<15} {'√Årbol Decisi√≥n':<15}")
print("-" * 60)
for i in range(len(feature_columns)):
    idx = indices[i]
    print(f"{i+1:<5} {feature_columns[idx]:<20} {importancias_rf[idx]:<15.4f} {importancias_dt[idx]:<15.4f}")

# Visualizaci√≥n de importancia
plt.figure(figsize=(12, 6))
x_pos = np.arange(len(feature_columns))
width = 0.35

plt.bar(x_pos - width/2, importancias_rf[indices], width, label='Random Forest', alpha=0.8)
plt.bar(x_pos + width/2, importancias_dt[indices], width, label='√Årbol de Decisi√≥n', alpha=0.8)

plt.xlabel('Caracter√≠sticas')
plt.ylabel('Importancia')
plt.title('Comparaci√≥n de Importancia de Caracter√≠sticas')
plt.xticks(x_pos, [feature_columns[i] for i in indices], rotation=45)
plt.legend()
plt.tight_layout()
plt.savefig('fraud_feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# 9. AN√ÅLISIS DE UMBRAL √ìPTIMO
print("\n9. AN√ÅLISIS DE UMBRAL √ìPTIMO")
print("-" * 40)

# Para Random Forest (mejor modelo), analizar diferentes umbrales
umbrales = np.linspace(0.1, 0.9, 9)
resultados_umbral = []

print("An√°lisis de umbral para Random Forest:")
print(f"{'Umbral':<8} {'Precision':<10} {'Recall':<8} {'F1':<8} {'Fraudes Detectados':<17}")
print("-" * 55)

for umbral in umbrales:
    pred_umbral = (rf_pred_proba >= umbral).astype(int)
    precision_u = precision_score(y_test, pred_umbral)
    recall_u = recall_score(y_test, pred_umbral)
    f1_u = f1_score(y_test, pred_umbral)
    fraudes_detectados = recall_u * y_test.sum()
    
    resultados_umbral.append([umbral, precision_u, recall_u, f1_u, fraudes_detectados])
    print(f"{umbral:<8.1f} {precision_u:<10.3f} {recall_u:<8.3f} {f1_u:<8.3f} {fraudes_detectados:<17.1f}")

# Encontrar umbral √≥ptimo (balance entre precision y recall)
resultados_df = pd.DataFrame(resultados_umbral, 
                           columns=['Umbral', 'Precision', 'Recall', 'F1', 'FraudesDetectados'])
umbral_optimo = resultados_df.loc[resultados_df['F1'].idxmax(), 'Umbral']
print(f"\nUmbral √≥ptimo basado en F1-Score: {umbral_optimo:.1f}")

# 10. CONCLUSIONES
print("\n10. CONCLUSIONES")
print("-" * 40)
print("üîç HALLAZGOS PRINCIPALES:")

# Comparar rendimiento general
if rf_metrics['recall'] > dt_metrics['recall']:
    print("‚Ä¢ Random Forest supera al √Årbol de Decisi√≥n en detecci√≥n de fraudes (mayor Recall)")
else:
    print("‚Ä¢ √Årbol de Decisi√≥n supera a Random Forest en detecci√≥n de fraudes (mayor Recall)")

print(f"‚Ä¢ Tasa de fraudes detectados:")
print(f"  - √Årbol de Decisi√≥n: {dt_metrics['recall']:.1%}")
print(f"  - Random Forest: {rf_metrics['recall']:.1%}")

print(f"‚Ä¢ Precisi√≥n en alertas:")
print(f"  - √Årbol de Decisi√≥n: {dt_metrics['precision']:.1%}")
print(f"  - Random Forest: {rf_metrics['precision']:.1%}")

# Caracter√≠sticas m√°s importantes
top_feature = feature_columns[np.argmax(importancias_rf)]
print(f"‚Ä¢ Caracter√≠stica m√°s importante: {top_feature}")

# Resumen ejecutivo
print(f"\nüìä RESUMEN EJECUTIVO:")
mejor_modelo_fraude = 'Random Forest' if rf_metrics['recall'] > dt_metrics['recall'] else '√Årbol de Decisi√≥n'
print(f"‚Ä¢ Mejor modelo para detecci√≥n de fraude: {mejor_modelo_fraude}")
print(f"‚Ä¢ Tasa de detecci√≥n de fraudes: {max(rf_metrics['recall'], dt_metrics['recall']):.1%}")
print(f"‚Ä¢ Falsos negativos (fraudes no detectados): {min(rf_metrics['fn'], dt_metrics['fn'])} de {y_test.sum()}")
print(f"‚Ä¢ El modelo puede identificar efectivamente patrones fraudulentos")
