# An√°lisis de Machine Learning: √Årboles de Decisi√≥n vs Random Forest

Este proyecto implementa tres an√°lisis completos de Machine Learning comparando el rendimiento de √Årboles de Decisi√≥n y Random Forest en diferentes tipos de problemas de clasificaci√≥n.

## üìã Datasets Analizados

1. **Titanic** - Supervivencia de pasajeros (Clasificaci√≥n Binaria)
2. **Iris** - Clasificaci√≥n de especies de flores (Clasificaci√≥n Multiclase)
3. **Detecci√≥n de Fraude** - Transacciones fraudulentas (Clasificaci√≥n Binaria Desbalanceada)

## üöÄ C√≥mo Ejecutar

### Prerrequisitos

Aseg√∫rate de tener instaladas las siguientes librer√≠as:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### Ejecuci√≥n de los Scripts

1. **An√°lisis de Titanic:**
```bash
cd "Taller 3"
python titanic_decision_tree_random_forest.py
```

2. **An√°lisis de Iris:**
```bash
cd "Taller 3"
python iris_decision_tree_random_forest.py
```

3. **An√°lisis de Detecci√≥n de Fraude:**
```bash
cd "Taller 3"
python fraud_detection_decision_tree_random_forest.py
```

## üìä Estructura del An√°lisis

Cada script sigue la misma estructura metodol√≥gica:

### 1. Introducci√≥n (10%)
- Presentaci√≥n del dataset
- Definici√≥n del problema de clasificaci√≥n
- Justificaci√≥n y desaf√≠os esperados

### 2. Preprocesamiento de Datos (20%)
- **Manejo de valores faltantes:** Imputaci√≥n con mediana/moda
- **Codificaci√≥n de variables categ√≥ricas:** LabelEncoder para variables binarias
- **Divisi√≥n de datos:** 80% entrenamiento, 20% prueba con estratificaci√≥n
- **Caracter√≠sticas derivadas:** Creaci√≥n de features adicionales cuando es relevante

### 3. Construcci√≥n y Entrenamiento de Modelos (20%)

#### √Årbol de Decisi√≥n:
- Configuraci√≥n de hiperpar√°metros (max_depth, min_samples_split, min_samples_leaf)
- Balance de clases cuando es necesario
- Explicaci√≥n de la configuraci√≥n elegida

#### Random Forest:
- Ensamble de 100 √°rboles
- Mismos hiperpar√°metros base que el √°rbol individual
- Uso de todos los cores disponibles (n_jobs=-1)

### 4. Evaluaci√≥n y Comparaci√≥n de Modelos (30%)

#### M√©tricas de Clasificaci√≥n Calculadas:

**Para todos los datasets:**
- **Accuracy:** Precisi√≥n general del modelo
- **Precision:** Proporci√≥n de predicciones positivas correctas
- **Recall (Sensibilidad):** Proporci√≥n de casos positivos detectados
- **F1-Score:** Media arm√≥nica entre Precision y Recall

**Visualizaciones incluidas:**
- **Matriz de Confusi√≥n:** Para ambos modelos con interpretaci√≥n detallada
- **Curvas ROC:** Con valores de AUC para comparaci√≥n
- **Gr√°ficos de barras:** Comparaci√≥n directa de m√©tricas
- **Importancia de caracter√≠sticas:** Ranking de features m√°s relevantes

**An√°lisis espec√≠ficos por dataset:**

- **Titanic:** Enfoque en supervivencia con an√°lisis demogr√°fico
- **Iris:** Clasificaci√≥n multiclase con ROC One-vs-Rest
- **Fraude:** √ânfasis especial en Recall (cr√≠tico para detectar fraudes)

### 5. An√°lisis Comparativo Detallado

- Comparaci√≥n tabular de todas las m√©tricas
- Identificaci√≥n del mejor modelo por F1-Score
- An√°lisis de fortalezas y debilidades de cada enfoque
- Recomendaciones espec√≠ficas para cada problema

## üìà Outputs Generados

Cada script genera:

### Archivos de Imagen:
- `{dataset}_analysis_results.png` - An√°lisis completo con m√∫ltiples gr√°ficos
- `{dataset}_feature_importance.png` - Importancia de caracter√≠sticas
- `iris_decision_tree.png` - Visualizaci√≥n del √°rbol (solo Iris)

### Reportes en Consola:
- An√°lisis paso a paso con m√©tricas detalladas
- Interpretaci√≥n de matrices de confusi√≥n
- Ranking de importancia de caracter√≠sticas
- Conclusiones y recomendaciones

## üéØ Caracter√≠sticas Especiales por Dataset

### Titanic:
- Manejo de datos faltantes en Age, Embarked, Fare
- Codificaci√≥n de variables categ√≥ricas (Sex, Embarked)
- An√°lisis de supervivencia por g√©nero y clase social

### Iris:
- Problema de clasificaci√≥n "perfecto" para demostrar capacidades
- Visualizaci√≥n completa del √°rbol de decisi√≥n
- ROC multiclase con One-vs-Rest
- An√°lisis de separabilidad de especies

### Detecci√≥n de Fraude:
- **√ânfasis en Recall:** Cr√≠tico para no perder fraudes
- **Balance de clases:** Manejo de dataset desbalanceado
- **An√°lisis de costo-beneficio:** Evaluaci√≥n del costo de errores
- **An√°lisis de umbral √≥ptimo:** Para optimizar detecci√≥n
- **Caracter√≠sticas derivadas:** AmountZScore, RiskScore, etc.

## üìù M√©tricas de Evaluaci√≥n Detalladas

### Matriz de Confusi√≥n (Para clasificaci√≥n binaria):
```
                Predicho
              No    S√≠
Real    No   TN    FP
        S√≠   FN    TP
```

- **TN (True Negatives):** Casos negativos correctamente clasificados
- **TP (True Positives):** Casos positivos correctamente clasificados
- **FP (False Positives):** Falsos positivos (Tipo I)
- **FN (False Negatives):** Falsos negativos (Tipo II)

### F√≥rmulas de M√©tricas:
- **Accuracy = (TP + TN) / (TP + TN + FP + FN)**
- **Precision = TP / (TP + FP)**
- **Recall = TP / (TP + FN)**
- **F1-Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)**
- **Specificity = TN / (TN + FP)**

## üèÜ Resultados Esperados

### Rendimiento General:
- **Random Forest** t√≠picamente supera a **√Årbol de Decisi√≥n** individual
- **RF** es m√°s robusto al overfitting
- **√Årbol individual** es m√°s interpretable

### Por Dataset:
- **Iris:** Ambos modelos logran >95% accuracy (dataset f√°cil)
- **Titanic:** RF ~82-85% accuracy vs DT ~80-83%
- **Fraude:** √ânfasis en maximizar Recall (>90% deseable)

## üõ†Ô∏è Configuraci√≥n de Hiperpar√°metros

### √Årbol de Decisi√≥n:
```python
DecisionTreeClassifier(
    max_depth=4-8,         # Seg√∫n complejidad del dataset
    min_samples_split=5-20, # Prevenir overfitting
    min_samples_leaf=2-10,  # Asegurar hojas significativas
    class_weight='balanced' # Para datasets desbalanceados
)
```

### Random Forest:
```python
RandomForestClassifier(
    n_estimators=100,       # N√∫mero de √°rboles
    max_depth=4-8,          # Igual que √°rbol individual
    min_samples_split=5-20, # Prevenir overfitting
    min_samples_leaf=2-10,  # Asegurar hojas significativas
    class_weight='balanced' # Para datasets desbalanceados
)
```

## üìö Conceptos Clave Implementados

### √Årboles de Decisi√≥n:
- Algoritmo de partici√≥n recursiva
- Criterios de divisi√≥n (Gini, Entropy)
- Podado para prevenir overfitting
- Interpretabilidad alta

### Random Forest:
- Ensamble de √°rboles (Bootstrap Aggregating)
- Selecci√≥n aleatoria de caracter√≠sticas
- Votaci√≥n por mayor√≠a
- Reducci√≥n de varianza

### T√©cnicas de Evaluaci√≥n:
- Validaci√≥n cruzada estratificada
- Curvas ROC y AUC
- An√°lisis de importancia de caracter√≠sticas
- M√©tricas espec√≠ficas por dominio

## üö® Consideraciones Especiales

### Para Detecci√≥n de Fraude:
- **Recall es m√°s importante que Precision**
- Costo asim√©trico de errores (FN >> FP)
- Necesidad de ajuste de umbrales
- Monitoreo continuo para nuevos patrones

### Para Clasificaci√≥n Multiclase (Iris):
- ROC One-vs-Rest para m√∫ltiples clases
- M√©tricas macro vs micro averaging
- Visualizaci√≥n de fronteras de decisi√≥n

### Manejo de Datos Desbalanceados:
- Uso de `class_weight='balanced'`
- Estratificaci√≥n en train-test split
- √ânfasis en m√©tricas apropiadas (F1, Recall)

## üìû Soporte y Extensiones

Para extender este an√°lisis:
1. Agregar validaci√≥n cruzada k-fold
2. Implementar GridSearchCV para optimizaci√≥n de hiperpar√°metros
3. Comparar con otros algoritmos (SVM, Neural Networks)
4. An√°lisis de curvas de aprendizaje
5. Implementar t√©cnicas de balanceo (SMOTE, undersampling)

---
**Nota:** Todos los scripts est√°n dise√±ados para ser educativos y completos, cubriendo todos los aspectos requeridos para el an√°lisis acad√©mico de modelos de Machine Learning.
