

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, auc
)
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaci√≥n
plt.style.use('default')
sns.set_palette("husl")

print("=" * 80)
print("AN√ÅLISIS DEL DATASET IRIS")
print("√Årboles de Decisi√≥n vs Random Forest")
print("=" * 80)


# Cargar el dataset
df = pd.read_csv('Taller_3\Iris\Iris.csv')

print(f"Dimensiones del dataset: {df.shape}")
print(f"Variables disponibles: {list(df.columns)}")
print(f"\nPrimeras 5 filas:")
print(df.head())

print(f"\nInformaci√≥n sobre valores faltantes:")
print(df.isnull().sum())

print(f"\nDistribuci√≥n de las especies (variable objetivo):")
species_counts = df['Species'].value_counts()
print(species_counts)

# Estad√≠sticas descriptivas
print(f"\nEstad√≠sticas descriptivas de las caracter√≠sticas:")
numeric_cols = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
print(df[numeric_cols].describe())

print("\n3. PREPROCESAMIENTO DE DATOS")
print("-" * 40)

# Crear una copia para el preprocesamiento
data = df.copy()

# Seleccionar caracter√≠sticas (excluir Id)
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
target = 'Species'

X = data[features]
y = data[target]

print(f"Caracter√≠sticas utilizadas: {features}")
print(f"Variable objetivo: {target}")
print(f"Forma de X: {X.shape}")
print(f"Clases √∫nicas: {y.unique()}")

# Codificar las etiquetas de especies
le = LabelEncoder()
y_encoded = le.fit_transform(y)

print(f"\nCodificaci√≥n de especies:")
for i, species in enumerate(le.classes_):
    print(f"  {species}: {i}")

# Divisi√≥n de datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
)

print(f"\nDivisi√≥n de datos:")
print(f"- Entrenamiento: {X_train.shape[0]} muestras")
print(f"- Prueba: {X_test.shape[0]} muestras")

# Distribuci√≥n en conjuntos de entrenamiento y prueba
print(f"\nDistribuci√≥n en entrenamiento: {np.bincount(y_train)}")
print(f"Distribuci√≥n en prueba: {np.bincount(y_test)}")

# 4. CONSTRUCCI√ìN Y ENTRENAMIENTO DE MODELOS
print("\n4. CONSTRUCCI√ìN Y ENTRENAMIENTO DE MODELOS")
print("-" * 40)

# 4.1 √Årbol de Decisi√≥n
print("\n4.1 √ÅRBOL DE DECISI√ìN - CONFIGURACI√ìN PARA MULTICLASE")
print("=" * 55)
print("CONCEPTO: √Årbol de decisi√≥n para clasificaci√≥n multiclase (3 especies de Iris)")
print("El √°rbol hace preguntas sobre las caracter√≠sticas de las flores para")
print("clasificarlas en una de las tres especies.")
print()
print("CONFIGURACI√ìN DE HIPERPAR√ÅMETROS PARA IRIS:")
print("‚îå‚îÄ max_depth=4:")
print("‚îÇ  ‚Ä¢ Profundidad m√°xima reducida (dataset peque√±o y simple)")
print("‚îÇ  ‚Ä¢ Iris es un problema relativamente f√°cil de clasificar")
print("‚îÇ  ‚Ä¢ Previene overfitting en un dataset de solo 150 muestras")
print("‚îÇ")
print("‚îå‚îÄ min_samples_split=5:")
print("‚îÇ  ‚Ä¢ Reducido vs Titanic debido al menor tama√±o del dataset")
print("‚îÇ  ‚Ä¢ Un nodo necesita al menos 5 muestras para dividirse")
print("‚îÇ  ‚Ä¢ Apropiado para dataset con 105 muestras de entrenamiento")
print("‚îÇ")
print("‚îå‚îÄ min_samples_leaf=2:")
print("‚îÇ  ‚Ä¢ Cada hoja debe tener al menos 2 muestras")
print("‚îÇ  ‚Ä¢ Valor bajo apropiado para dataset peque√±o pero balanceado")
print("‚îÇ  ‚Ä¢ Permite capturar patrones espec√≠ficos de cada especie")
print("‚îÇ")
print("‚îî‚îÄ random_state=42: Reproducibilidad de resultados")
print()
print("ESTRATEGIA MULTICLASE:")
print("‚Ä¢ El √°rbol maneja naturalmente clasificaci√≥n multiclase")
print("‚Ä¢ Cada divisi√≥n busca la mejor separaci√≥n entre las 3 clases")
print("‚Ä¢ Las hojas contendr√°n muestras mayoritariamente de una especie")
print()

dt_classifier = DecisionTreeClassifier(
    max_depth=4,           
    min_samples_split=5,   
    min_samples_leaf=2,    
    random_state=42
)

print("Entrenando √Årbol de Decisi√≥n para clasificaci√≥n multiclase...")
dt_classifier.fit(X_train, y_train)
print("‚úì √Årbol de Decisi√≥n entrenado exitosamente")
print(f"  ‚Ä¢ Profundidad m√°xima configurada: {dt_classifier.max_depth}")
print(f"  ‚Ä¢ Profundidad real alcanzada: {dt_classifier.get_depth()}")
print(f"  ‚Ä¢ N√∫mero de hojas: {dt_classifier.get_n_leaves()}")
print(f"  ‚Ä¢ Clases manejadas: {len(dt_classifier.classes_)} especies")

# 4.2 Random Forest
print("\n4.2 RANDOM FOREST - ENSEMBLE PARA MULTICLASE")
print("=" * 55)
print("CONCEPTO: Ensemble de 100 √°rboles trabajando juntos para clasificar")
print("las especies de Iris. Cada √°rbol 'vota' por una especie y gana la mayor√≠a.")
print()
print("VENTAJAS DEL ENSEMBLE EN MULTICLASE:")
print("‚îå‚îÄ Robustez:")
print("‚îÇ  ‚Ä¢ Si un √°rbol se confunde entre dos especies similares,")
print("‚îÇ  ‚Ä¢ otros √°rboles pueden corregir el error")
print("‚îÇ  ‚Ä¢ Reduce la variabilidad en las predicciones")
print("‚îÇ")
print("‚îå‚îÄ Mejor separaci√≥n de clases:")
print("‚îÇ  ‚Ä¢ Diferentes √°rboles pueden especializarse en separar")
print("‚îÇ  ‚Ä¢ pares espec√≠ficos de especies (setosa vs resto, etc.)")
print("‚îÇ  ‚Ä¢ Captura mejor la complejidad de los l√≠mites de decisi√≥n")
print("‚îÇ")
print("‚îî‚îÄ Estimaci√≥n de confianza:")
print("   ‚Ä¢ El porcentaje de votos indica qu√© tan 'seguro' est√° el modelo")
print("   ‚Ä¢ √ötil para identificar casos ambiguos entre especies")
print()
print("CONFIGURACI√ìN DE HIPERPAR√ÅMETROS:")
print("‚îå‚îÄ n_estimators=100:")
print("‚îÇ  ‚Ä¢ 100 √°rboles en el bosque")
print("‚îÇ  ‚Ä¢ N√∫mero est√°ndar que balancea rendimiento y eficiencia")
print("‚îÇ  ‚Ä¢ Cada √°rbol entrena con ~67 muestras (bootstrap)")
print("‚îÇ")
print("‚îå‚îÄ max_depth=4:")
print("‚îÇ  ‚Ä¢ Cada √°rbol individual es relativamente simple")
print("‚îÇ  ‚Ä¢ La complejidad surge del ensemble, no de √°rboles profundos")
print("‚îÇ  ‚Ä¢ Apropiado para el dataset Iris")
print("‚îÇ")
print("‚îå‚îÄ min_samples_split=5 y min_samples_leaf=2:")
print("‚îÇ  ‚Ä¢ Par√°metros ajustados al tama√±o del dataset")
print("‚îÇ  ‚Ä¢ Permiten que cada √°rbol capture patrones espec√≠ficos")
print("‚îÇ  ‚Ä¢ Evitan overfitting manteniendo la simplicidad")
print("‚îÇ")
print("‚îî‚îÄ random_state=42: Control de la aleatoriedad del ensemble")
print()

rf_classifier = RandomForestClassifier(
    n_estimators=100,      
    max_depth=4,           
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

print("Entrenando Random Forest (100 √°rboles para 3 especies)...")
rf_classifier.fit(X_train, y_train)
print("‚úì Random Forest entrenado exitosamente")
print(f"  ‚Ä¢ N√∫mero de √°rboles: {rf_classifier.n_estimators}")
print(f"  ‚Ä¢ Profundidad m√°xima por √°rbol: {rf_classifier.max_depth}")
print(f"  ‚Ä¢ Caracter√≠sticas consideradas por divisi√≥n: ‚àö{len(X_train.columns)} ‚âà {int(np.sqrt(len(X_train.columns)))}")
print(f"  ‚Ä¢ Muestras de entrenamiento por √°rbol: ~{int(0.632 * len(X_train))}")
print(f"  ‚Ä¢ Especies clasificadas: {len(rf_classifier.classes_)}")

print("\nüå∏ ESPECIALIZACI√ìN PARA CLASIFICACI√ìN DE IRIS:")
print("‚Ä¢ Setosa: Generalmente f√°cil de separar (caracter√≠sticas distintivas)")
print("‚Ä¢ Versicolor vs Virginica: M√°s desafiante, aqu√≠ brilla el ensemble")
print("‚Ä¢ El Random Forest puede crear m√∫ltiples estrategias de separaci√≥n")
print("‚Ä¢ Cada √°rbol puede usar diferentes combinaciones de caracter√≠sticas")

# 5. EVALUACI√ìN Y COMPARACI√ìN DE MODELOS
print("\n5. EVALUACI√ìN Y COMPARACI√ìN DE MODELOS")
print("-" * 40)

# Predicciones
dt_pred = dt_classifier.predict(X_test)
dt_pred_proba = dt_classifier.predict_proba(X_test)

rf_pred = rf_classifier.predict(X_test)
rf_pred_proba = rf_classifier.predict_proba(X_test)

# Funci√≥n para calcular m√©tricas multiclase
def calcular_metricas_multiclase(y_true, y_pred, y_pred_proba, modelo_nombre, class_names):
    print(f"\nM√âTRICAS PARA {modelo_nombre.upper()}")
    print("-" * 30)
    
    # M√©tricas b√°sicas
    accuracy = accuracy_score(y_true, y_pred)
    precision_macro = precision_score(y_true, y_pred, average='macro')
    recall_macro = recall_score(y_true, y_pred, average='macro')
    f1_macro = f1_score(y_true, y_pred, average='macro')
    
    precision_micro = precision_score(y_true, y_pred, average='micro')
    recall_micro = recall_score(y_true, y_pred, average='micro')
    f1_micro = f1_score(y_true, y_pred, average='micro')
    
    print(f"Precisi√≥n (Accuracy): {accuracy:.4f}")
    print(f"\nM√©tricas Macro (promedio no ponderado):")
    print(f"  Precisi√≥n (Precision): {precision_macro:.4f}")
    print(f"  Exhaustividad (Recall): {recall_macro:.4f}")
    print(f"  Puntuaci√≥n F1: {f1_macro:.4f}")
    
    print(f"\nM√©tricas Micro (promedio ponderado):")
    print(f"  Precisi√≥n (Precision): {precision_micro:.4f}")
    print(f"  Exhaustividad (Recall): {recall_micro:.4f}")
    print(f"  Puntuaci√≥n F1: {f1_micro:.4f}")
    
    # Matriz de confusi√≥n
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nMatriz de Confusi√≥n:")
    print("           Predicho")
    print(f"           {class_names[0][:4]:>6} {class_names[1][:4]:>6} {class_names[2][:4]:>6}")
    for i, real_class in enumerate(class_names):
        print(f"Real {real_class[:4]:>4}: {cm[i,0]:6d} {cm[i,1]:6d} {cm[i,2]:6d}")
    
    # Reporte de clasificaci√≥n por clase
    print(f"\nReporte detallado por clase:")
    class_report = classification_report(y_true, y_pred, target_names=class_names, 
                                       output_dict=True)
    for i, class_name in enumerate(class_names):
        metrics = class_report[class_name]
        print(f"  {class_name}:")
        print(f"    Precision: {metrics['precision']:.4f}")
        print(f"    Recall: {metrics['recall']:.4f}")
        print(f"    F1-Score: {metrics['f1-score']:.4f}")
    
    return {
        'accuracy': accuracy, 'precision_macro': precision_macro, 
        'recall_macro': recall_macro, 'f1_macro': f1_macro,
        'precision_micro': precision_micro, 'recall_micro': recall_micro, 
        'f1_micro': f1_micro, 'cm': cm, 'class_report': class_report,
        'pred_proba': y_pred_proba
    }

# Nombres de las clases
class_names = le.classes_

# Calcular m√©tricas para ambos modelos
dt_metrics = calcular_metricas_multiclase(y_test, dt_pred, dt_pred_proba, 
                                        "√Årbol de Decisi√≥n", class_names)
rf_metrics = calcular_metricas_multiclase(y_test, rf_pred, rf_pred_proba, 
                                        "Random Forest", class_names)

# 6. AN√ÅLISIS COMPARATIVO
print("\n6. AN√ÅLISIS COMPARATIVO")
print("-" * 40)

# Comparaci√≥n de m√©tricas
metricas_comparacion = pd.DataFrame({
    '√Årbol de Decisi√≥n': [
        dt_metrics['accuracy'], dt_metrics['precision_macro'], 
        dt_metrics['recall_macro'], dt_metrics['f1_macro']
    ],
    'Random Forest': [
        rf_metrics['accuracy'], rf_metrics['precision_macro'], 
        rf_metrics['recall_macro'], rf_metrics['f1_macro']
    ]
}, index=['Accuracy', 'Precision (Macro)', 'Recall (Macro)', 'F1-Score (Macro)'])

print("Comparaci√≥n de M√©tricas:")
print(metricas_comparacion.round(4))

# Determinar el mejor modelo
mejor_modelo = 'Random Forest' if rf_metrics['f1_macro'] > dt_metrics['f1_macro'] else '√Årbol de Decisi√≥n'
print(f"\nMejor modelo basado en F1-Score Macro: {mejor_modelo}")

# 7. VISUALIZACIONES
print("\n7. GENERANDO VISUALIZACIONES")
print("-" * 40)

# Configurar subplots
fig = plt.figure(figsize=(20, 15))

# 7.1 Distribuci√≥n de datos por especies (subplot 1)
plt.subplot(3, 3, 1)
sns.scatterplot(data=df, x='SepalLengthCm', y='SepalWidthCm', hue='Species')
plt.title('Distribuci√≥n: S√©palo Longitud vs Ancho')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

plt.subplot(3, 3, 2)
sns.scatterplot(data=df, x='PetalLengthCm', y='PetalWidthCm', hue='Species')
plt.title('Distribuci√≥n: P√©talo Longitud vs Ancho')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

# 7.2 Matrices de Confusi√≥n
plt.subplot(3, 3, 4)
sns.heatmap(dt_metrics['cm'], annot=True, fmt='d', cmap='Blues',
           xticklabels=[name[:4] for name in class_names],
           yticklabels=[name[:4] for name in class_names])
plt.title('Matriz de Confusi√≥n - √Årbol de Decisi√≥n')
plt.ylabel('Valores Reales')
plt.xlabel('Valores Predichos')

plt.subplot(3, 3, 5)
sns.heatmap(rf_metrics['cm'], annot=True, fmt='d', cmap='Greens',
           xticklabels=[name[:4] for name in class_names],
           yticklabels=[name[:4] for name in class_names])
plt.title('Matriz de Confusi√≥n - Random Forest')
plt.ylabel('Valores Reales')
plt.xlabel('Valores Predichos')

# 7.3 Comparaci√≥n de M√©tricas
plt.subplot(3, 3, 6)
metricas_comparacion.plot(kind='bar', ax=plt.gca())
plt.title('Comparaci√≥n de M√©tricas')
plt.ylabel('Puntuaci√≥n')
plt.xticks(rotation=45)
plt.legend()

# 7.4 ROC Curves para clasificaci√≥n multiclase (One-vs-Rest)
# Binarizar las etiquetas para ROC multiclase
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
n_classes = 3

plt.subplot(3, 3, 7)
colors = ['blue', 'red', 'green']
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], dt_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=colors[i], lw=2,
             label=f'{class_names[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('ROC - √Årbol de Decisi√≥n')
plt.legend(loc="lower right")

plt.subplot(3, 3, 8)
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], rf_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=colors[i], lw=2,
             label=f'{class_names[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('ROC - Random Forest')
plt.legend(loc="lower right")

# 7.5 Importancia de caracter√≠sticas (Random Forest)
plt.subplot(3, 3, 9)
importancias = rf_classifier.feature_importances_
indices = np.argsort(importancias)[::-1]
plt.bar(range(len(importancias)), importancias[indices])
plt.xticks(range(len(importancias)), [features[i] for i in indices], rotation=45)
plt.title('Importancia de Caracter√≠sticas - RF')
plt.ylabel('Importancia')

plt.suptitle('An√°lisis Iris: √Årboles de Decisi√≥n vs Random Forest', fontsize=16)
plt.tight_layout()
plt.savefig('iris_analysis_results.png', dpi=300, bbox_inches='tight')
plt.show()

# 8. VISUALIZACI√ìN DEL √ÅRBOL DE DECISI√ìN
print("\n8. VISUALIZACI√ìN DEL √ÅRBOL DE DECISI√ìN")
print("-" * 40)

plt.figure(figsize=(20, 10))
plot_tree(dt_classifier, 
          feature_names=features,
          class_names=class_names,
          filled=True,
          rounded=True,
          fontsize=10)
plt.title('√Årbol de Decisi√≥n - Dataset Iris')
plt.savefig('iris_decision_tree.png', dpi=300, bbox_inches='tight')
plt.show()

# 9. IMPORTANCIA DE CARACTER√çSTICAS DETALLADA
print("\n9. IMPORTANCIA DE CARACTER√çSTICAS")
print("-" * 40)

importancias = rf_classifier.feature_importances_
indices_importancia = np.argsort(importancias)[::-1]

print("Ranking de importancia de caracter√≠sticas (Random Forest):")
for i in range(len(features)):
    print(f"{i+1}. {features[indices_importancia[i]]}: "
          f"{importancias[indices_importancia[i]]:.4f}")

# Comparar importancias entre modelos
print("\nComparaci√≥n de importancias:")
dt_importancias = dt_classifier.feature_importances_
rf_importancias = rf_classifier.feature_importances_

importancia_df = pd.DataFrame({
    'Caracter√≠stica': features,
    '√Årbol de Decisi√≥n': dt_importancias,
    'Random Forest': rf_importancias
})
print(importancia_df.round(4))


# An√°lisis espec√≠fico de rendimiento
if dt_metrics['accuracy'] > 0.95 and rf_metrics['accuracy'] > 0.95:
    print("‚Ä¢ Ambos modelos muestran excelente rendimiento en este dataset")
elif rf_metrics['accuracy'] > dt_metrics['accuracy']:
    print("‚Ä¢ Random Forest supera al √Årbol de Decisi√≥n en este caso")
else:
    print("‚Ä¢ El √Årbol de Decisi√≥n muestra mejor rendimiento")

print(f"\n‚úì An√°lisis completado. Archivos guardados:")
print("  - iris_analysis_results.png")
print("  - iris_decision_tree.png")
